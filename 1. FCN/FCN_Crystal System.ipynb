{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, metrics\n",
    "import random\n",
    "import os\n",
    "\n",
    "File_Path = \"Test_data.h5\"\n",
    "weights_PATH = \"FCN_CS.ckpt\"\n",
    "\n",
    "ICSD = h5py.File(File_Path, 'r')\n",
    "stack = ICSD['data'][:,:]\n",
    "\n",
    "data = stack[:,:-1813]/100\n",
    "\n",
    "x_data = data.reshape(-1,data.shape[1],1)\n",
    "y_data_cs = stack[:,-5]-1\n",
    "y_data_cs = tf.keras.utils.to_categorical(y_data_cs, num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN_Crystal System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x28b655657c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_rate= 0.2\n",
    "drop_rate_2= 0.4\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "FCNcs_inputs = keras.Input(shape=(8192, 1))\n",
    "c1=layers.Conv1D(filters=16, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(FCNcs_inputs)\n",
    "p1=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c1)\n",
    "p1=layers.Dropout(rate=drop_rate)(p1)\n",
    "c2=layers.Conv1D(filters=16, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p1)\n",
    "p2=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c2)\n",
    "p2=layers.Dropout(rate=drop_rate)(p2)\n",
    "c3=layers.Conv1D(filters=32, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p2)\n",
    "p3=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c3)\n",
    "p3=layers.Dropout(rate=drop_rate)(p3)\n",
    "c4=layers.Conv1D(filters=32, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p3)\n",
    "p4=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c4)\n",
    "p4=layers.Dropout(rate=drop_rate)(p4)\n",
    "c5=layers.Conv1D(filters=64, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p4)\n",
    "p5=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c5)\n",
    "p5=layers.Dropout(rate=drop_rate)(p5)\n",
    "c6=layers.Conv1D(filters=64, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p5)\n",
    "p6=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c6)\n",
    "p6=layers.Dropout(rate=drop_rate)(p6)\n",
    "c7=layers.Conv1D(filters=128, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p6)\n",
    "p7=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c7)\n",
    "p7=layers.Dropout(rate=drop_rate)(p7)\n",
    "c8=layers.Conv1D(filters=128, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p7)\n",
    "p8=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c8)\n",
    "p8=layers.Dropout(rate=drop_rate)(p8)\n",
    "c9=layers.Conv1D(filters=256, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p8)\n",
    "p9=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c9)\n",
    "p9=layers.Dropout(rate=drop_rate)(p9)\n",
    "c10=layers.Conv1D(filters=256, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p9)\n",
    "p10=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c10)\n",
    "p10=layers.Dropout(rate=drop_rate)(p10)\n",
    "c11=layers.Conv1D(filters=512, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p10)\n",
    "p11=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c11)\n",
    "p11=layers.Dropout(rate=drop_rate)(p11)\n",
    "c12=layers.Conv1D(filters=512, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p11)\n",
    "p12=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c12)\n",
    "p12=layers.Dropout(rate=drop_rate_2)(p12)\n",
    "c13=layers.Conv1D(filters=64, kernel_size=3, strides=1,padding='same', kernel_initializer=initializer)(p12)\n",
    "p13=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c13)\n",
    "p13=layers.Dropout(rate=drop_rate_2)(p13)\n",
    "\n",
    "c14=layers.Conv1D(filters=7, kernel_size=1, strides=1,padding='same', kernel_initializer=initializer)(p13)\n",
    "f1= layers.Flatten()(c14)\n",
    "\n",
    "FCNcs_outputs=tf.nn.softmax(f1)\n",
    "\n",
    "FCN = keras.Model(inputs=[FCNcs_inputs], outputs=[FCNcs_outputs], name=\"FCN\")\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "FCN.compile(optimizer=opt,  loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "FCN.load_weights(weights_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26489102840423584, 0.949999988079071]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCN.evaluate(x_data, y_data_cs, batch_size = len(x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

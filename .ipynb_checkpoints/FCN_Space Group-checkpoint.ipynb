{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, metrics\n",
    "import random\n",
    "import os\n",
    "\n",
    "File_Path = \"Test_data.h5\"\n",
    "weights_PATH = \"FCN_SG.ckpt\"\n",
    "\n",
    "ICSD = h5py.File(File_Path, 'r')\n",
    "stack=ICSD['data'][:,:]\n",
    "\n",
    "data = stack[:,:-1813]/100\n",
    "\n",
    "x_data = data.reshape(-1,data.shape[1],1)\n",
    "y_data_sg = stack[:,-3]-1\n",
    "y_data_sg = tf.keras.utils.to_categorical(y_data_sg, num_classes=230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN_Space Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25875090908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_rate= 0.2\n",
    "drop_rate_2= 0.4\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "FCNsg_inputs = keras.Input(shape=(8192, 1))\n",
    "\n",
    "c1=layers.Conv1D(filters=16, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(FCNsg_inputs)\n",
    "p1=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c1)\n",
    "p1=layers.Dropout(rate=drop_rate)(p1)\n",
    "c2=layers.Conv1D(filters=16, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p1)\n",
    "p2=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c2)\n",
    "p2=layers.Dropout(rate=drop_rate)(p2)\n",
    "c3=layers.Conv1D(filters=32, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p2)\n",
    "p3=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c3)\n",
    "p3=layers.Dropout(rate=drop_rate)(p3)\n",
    "c4=layers.Conv1D(filters=32, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p3)\n",
    "p4=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c4)\n",
    "p4=layers.Dropout(rate=drop_rate)(p4)\n",
    "c5=layers.Conv1D(filters=64, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p4)\n",
    "p5=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c5)\n",
    "p5=layers.Dropout(rate=drop_rate)(p5)\n",
    "c6=layers.Conv1D(filters=64, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p5)\n",
    "p6=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c6)\n",
    "p6=layers.Dropout(rate=drop_rate)(p6)\n",
    "c7=layers.Conv1D(filters=128, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p6)\n",
    "p7=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c7)\n",
    "p7=layers.Dropout(rate=drop_rate)(p7)\n",
    "c8=layers.Conv1D(filters=128, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p7)\n",
    "p8=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c8)\n",
    "p8=layers.Dropout(rate=drop_rate)(p8)\n",
    "c9=layers.Conv1D(filters=256, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p8)\n",
    "p9=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c9)\n",
    "p9=layers.Dropout(rate=drop_rate)(p9)\n",
    "c10=layers.Conv1D(filters=256, kernel_size=3, strides=1,padding='same', activation=tf.keras.layers.LeakyReLU(), \n",
    "                        kernel_initializer=initializer)(p9)\n",
    "p10=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c10)\n",
    "p10=layers.Dropout(rate=drop_rate)(p10)\n",
    "c11=layers.Conv1D(filters=512, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p10)\n",
    "p11=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c11)\n",
    "p11=layers.Dropout(rate=drop_rate)(p11)\n",
    "c12=layers.Conv1D(filters=512, kernel_size=3, strides=1,padding='same',activation=tf.keras.layers.LeakyReLU(), \n",
    "                         kernel_initializer=initializer)(p11)\n",
    "p12=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c12)\n",
    "p12=layers.Dropout(rate=drop_rate_2)(p12)\n",
    "c13=layers.Conv1D(filters=256, kernel_size=3, strides=1,padding='same', kernel_initializer=initializer)(p12)\n",
    "p13=layers.MaxPooling1D(pool_size=2, strides=2, padding='same')(c13)\n",
    "p13=layers.Dropout(rate=drop_rate_2)(p13)\n",
    "\n",
    "c14=layers.Conv1D(filters=230, kernel_size=1, strides=1,padding='same', kernel_initializer=initializer)(p13)\n",
    "f1= layers.Flatten()(c14)\n",
    "\n",
    "FCNsg_outputs=tf.nn.softmax(f1)\n",
    "\n",
    "FCN = tf.keras.Model(inputs=[FCNsg_inputs], outputs=[FCNsg_outputs], name=\"FCN\")\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "FCN.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "FCN.load_weights(weights_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.7700 - top_k_categorical_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.746422529220581, 0.7699999809265137, 0.9700000286102295]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCN.evaluate(x_data, y_data_sg, batch_size = len(x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
